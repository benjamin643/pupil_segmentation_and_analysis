---
title: "scalar features"
output: html_document
date: '2022-06-27'
---

```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(broom)
library(emmeans)
library(ggpubr)
library(patchwork)
library(scales)
library(RColorBrewer)
library(readxl)
library(qgam)
library(kableExtra)


library(pracma)
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  fig.width = 8,
  fig.height = 6
)
theme_set(theme_bw() + theme(legend.position = "bottom"))
```   

# To add slope of drop out 

## R Markdown

```{r}
## cleaned final data 
pupils = read_csv(here::here("data", "pupils_clean_register.csv"))
pupils = pupils[!is.na(pupils$timeid), ]


## original data 

setwd("/Users/benjaminsteinhart/Desktop/image_seg/results/full_output_water_2part/")

files <- dir(path = "/Users/benjaminsteinhart/Desktop/image_seg/results/full_output_water_2part/",pattern = "*.csv")


original <- files %>%
  map(read_csv) %>%    # read in all the files individually, using
                       # the function read_csv() from the readr package
  reduce(rbind) 
original$timeid = substr(original$Image, 1, 11)
original$frame = parse_number(substr(original$Image, 20, 28))

# if fixed in the program, can delete this
original$TimeR = original$TimeR - original$Time # right eye segmented after left but time was not reset so subtracting that time here to get true right time 

# formatting into long format
# center x coordinate for right and left eye
centerx = original %>% select(Image, centerx, centerxR) %>% pivot_longer(cols = c("centerx", "centerxR"), names_to ="eye", values_to = "centerx") %>% mutate(eye = if_else(eye == "centerx","Left", "Right"))

# center y coordinate for right and left eye
centery = original %>% select(Image, centery, centeryR, frame, timeid) %>% pivot_longer(cols = c("centery", "centeryR"), names_to ="eye", values_to = "centery") %>% mutate(eye = if_else(eye == "centery","Left", "Right"))

# time for right and left eye
time = original %>% select(Image, Time, TimeR) %>% pivot_longer(cols = c("Time", "TimeR"), names_to ="eye", values_to = "time") %>% mutate(eye = if_else(eye == "Time","Left", "Right"))

# major axis size right and left eye
major_axis = original %>% select(Image, major_axis, major_axisR) %>% pivot_longer(cols = c("major_axis", "major_axisR"), names_to ="eye", values_to = "major_axis") %>% mutate(eye = if_else(eye == "major_axis","Left", "Right"))

# minor axis size right and left eye
minor_axis = original %>% select(Image, minor_axis, minor_axisR) %>% pivot_longer(cols = c("minor_axis", "minor_axisR"), names_to ="eye", values_to = "minor_axis") %>% mutate(eye = if_else(eye == "minor_axis","Left", "Right"))

# eccentricity size right and left eye
eccentricity = original %>% select(Image, eccentricity, eccentricityR) %>% pivot_longer(cols = c("eccentricity", "eccentricityR"), names_to ="eye", values_to = "eccentricity") %>% mutate(eye = if_else(eye == "eccentricity","Left", "Right"))

## Joining long data sets

original = left_join(centerx, centery) %>% left_join(.,time) %>% left_join(.,major_axis) %>% left_join(.,minor_axis) %>% left_join(.,eccentricity) 

original = original %>% select(timeid, frame, eye, time, major_axis, minor_axis, eccentricity, centerx, centery)

# factoring eye
original$eye = factor(original$eye)

## Creating percent change variable


original = original %>% group_by(timeid, eye) %>%  mutate(initial =first(major_axis)) %>% ungroup()

original = original %>% group_by(timeid, eye) %>% mutate(percent_change = ((major_axis - initial) / initial)*100) %>% ungroup()
```




# Saving trimmed set for julia

```{r, eval = FALSE}
# importing user_group data from cannabis_variables: A is occasional, B is non-user, C is daily
user_groups = read_xlsx("/Users/benjaminsteinhart/Desktop/data/202002_brooks_marijuana/20200121_demographic_data/all_demos_and_blood.xlsx")
#modifying user group to say classification insteado of the letter
user_groups = user_groups %>% mutate(user_type = case_when(
  group == "A" ~ "occasional",
  group == "B" ~ "non-user",
  group == "C" ~ "daily"
))
user_groups = user_groups %>% select(subject_id, user_type)

pupils$subject_id = substr(pupils$timeid, 1, 7) ## participant id 
pupils$time = substr(pupils$timeid, 8, 15) # time point



pupils = left_join(pupils, user_groups)

pupils$user_type = factor(pupils$user_type, levels = c("non-user", "occasional", "daily"))

pupils_trim = pupils %>% select(subject_id, time, user_type, eye, percent_change, centered)


filename = "pupils_trim.csv"

write_csv(pupils_trim, file = here::here("data", filename))


ggplot(pupils_trim %>% filter(subject_id == "001-061", eye == "Left", time == "pre2"), aes(x = centered, y = percent_change )) + geom_line()





```


```{r, eval = FALSE}
ggplot(pupils %>% filter(eye == "Left", time == "post"), aes(x = frame, y = percent_change, colour = subject_id)) + geom_line(alpha = 0.2)+ theme(legend.position = "none") + facet_wrap(~eye)
ggplot(pupils %>% filter(eye == "Right", time == "post"), aes(x = frame, y = percent_change, colour = subject_id)) + geom_line(alpha = 0.2)+ theme(legend.position = "none") + facet_wrap(~eye)

ggplot(pupils %>% filter(eye == "Left", time == "pre2"), aes(x = centered, y = percent_change, colour = subject_id)) + geom_line(alpha = 0.2)+ facet_wrap(~eye)
ggplot(pupils %>% filter(eye == "Right", time == "pre2"), aes(x = frame, y = percent_change, colour = subject_id)) + geom_line(alpha = 0.2)+ theme(legend.position = "none") + facet_wrap(~eye)

```

##  Point of minimum constriction / Time to minimum constriction from start of the test 


```{r}
scalars = pupils %>% filter(centered > 0) %>% group_by(timeid, eye) %>% mutate(min_constriction = min(percent_change), duration = max(centered, na.rm=TRUE))  %>% filter(percent_change== min_constriction) %>% select(timeid, eye, min_constriction, centered, duration) %>% unique() %>% ungroup()

scalars$frame_min = scalars$centered


```


## average size at end of test 

* taking average percent change over the last 30 frames (one second of test)

```{r}

participant_vec = unique(pupils$timeid)

eyes = c("Left", "Right")

storage_matrix = matrix(NA, nrow = length(participant_vec)*2, ncol = 3)

count = 0
for (iter in 1:length(participant_vec)){
  for(iter_eye in 1:2){
    
    count = count+1
    
    temp = pupils %>% filter(timeid == participant_vec[iter], eye == eyes[iter_eye])

    temp = temp[(nrow(temp)-30):nrow(temp), ]
    
    avg_end_percent = mean(temp$percent_change)
  
    storage_matrix[count, ] = c(participant_vec[iter], eyes[iter_eye], avg_end_percent )
      
      }}



storage_matrix = as.tibble(storage_matrix)
colnames(storage_matrix) = c("timeid", "eye", "avg_end_percent")
scalars = left_join(scalars, storage_matrix)
scalars$avg_end_percent = as.numeric(scalars$avg_end_percent)

```

## "end" of test

* taking 15th frame prior to end since took average of last 30 frames (1 second)

```{r}
scalars = left_join(scalars, pupils %>% group_by(timeid, eye) %>% mutate(last_obs = last(centered) - 15) %>% ungroup() %>% select(timeid, eye, last_obs) %>% unique())

```


## Slope from min constriction to end

```{r}
scalars = scalars %>% group_by(timeid, eye) %>% mutate(slope = (avg_end_percent - min_constriction)/(last_obs - centered)) %>% ungroup()

scalars %>% group_by(timeid, eye) %>% mutate(slope = (last_obs - centered)) %>% ungroup() %>% arrange(slope)
```

## area under the curve 

```{r, }

frame_minimum = scalars %>% select(timeid, frame_min, eye) %>% unique()


pupils = left_join(pupils, frame_minimum)

auc_all = pupils %>% filter(centered>=frame_min) %>% group_by(timeid, eye) %>% mutate(AUC = trapz(centered,percent_change)) %>% ungroup() %>% select(timeid, eye, AUC) %>% unique()

scalars = left_join(scalars, auc_all)

scalars$auc_duration = scalars$duration - scalars$frame_min

scalars$AUC = scalars$AUC/scalars$auc_duration


```


* can flag by positive auc, 65pre2 at least has wrong starting point


## Average size from point of minimum constriction to end of test 

```{r}

participant_vec = unique(pupils$timeid)

eyes = c("Left", "Right")

storage_matrix = matrix(NA, nrow = length(participant_vec)*2, ncol = 3)

count = 0
for (iter in 1:length(participant_vec)){
  for(iter_eye in 1:2){
    
    count = count+1
    
    temp = pupils %>% filter(timeid == participant_vec[iter], eye == eyes[iter_eye])

    if(nrow(temp)>0){
    
    temp_min = which.min(temp %>% filter(centered >=0) %>% arrange(centered) %>% select(yhat2) %>% pull())
    
    temp = temp[temp_min:nrow(temp), ] 
    
    avg_end_percent = mean(temp$percent_change)
  
    storage_matrix[count, ] = c(participant_vec[iter], eyes[iter_eye], avg_end_percent )
      
      }}}



storage_matrix = as.tibble(storage_matrix)
colnames(storage_matrix) = c("timeid", "eye", "avg_percent_change_min_end")

scalars = left_join(scalars, storage_matrix)
scalars$avg_percent_change_min_end = as.numeric(scalars$avg_percent_change_min_end)
```


## Slope from beginning of test to min constrction

```{r}
scalars$beginning_slope = scalars$min_constriction/scalars$frame_min

```


## Completion Rate 


```{r}

# n_obs = pupils %>% group_by(timeid, eye) %>% mutate(completed_obs = max(centered, na.rm=TRUE)) %>% select(timeid, eye, completed_obs) %>% unique() %>% ungroup()

participant_id = pupils$timeid %>% unique()

storage_matrix = matrix(NA, nrow = length(participant_id)*2, ncol = 3)

eyes = c("Left", "Right")

count = 0
for (iter_eye in 1:2){
  for (iter1 in 1:length(participant_id)){
    count = count + 1
    left_eye = pupils %>% filter(timeid == participant_id[iter1], eye == eyes[iter_eye], centered >=0) %>% select(timeid, eye, major_axis) #creating temporary data frame
    
    left_eye = left_eye[complete.cases(left_eye),]
    # acf_clean = round(acf(left_eye$major_axis, pl = FALSE)$acf[2],4)

    n_obs = nrow(left_eye) # number of data points in original

    storage_matrix[count, ] = c(participant_id[iter1], n_obs, eyes[iter_eye])
  }
}

storage_matrix = as.data.frame(storage_matrix)

storage_matrix = rename(storage_matrix, timeid = V1)
storage_matrix = rename(storage_matrix, completed_obs = V2)
storage_matrix = rename(storage_matrix, eye = V3)


storage_matrix %>% skimr::skim()

scalars = left_join(scalars, storage_matrix)

scalars$completed_obs = as.numeric(scalars$completed_obs)

scalars %>% skimr::skim()

```


# Merging User Group into scalar features

```{r}

scalars$subject_id = substr(scalars$timeid, 1, 7) ## participant id 
scalars$time = substr(scalars$timeid, 8, 15) # time point


pupils$subject_id = substr(pupils$timeid, 1, 7) ## participant id 
pupils$time = substr(pupils$timeid, 8, 15) # time point

# importing user_group data from cannabis_variables: A is occasional, B is non-user, C is daily
user_groups = read_xlsx("/Users/benjaminsteinhart/Desktop/data/202002_brooks_marijuana/20200121_demographic_data/all_demos_and_blood.xlsx")
#modifying user group to say classification insteado of the letter
user_groups = user_groups %>% mutate(user_type = case_when(
  group == "A" ~ "occasional",
  group == "B" ~ "non-user",
  group == "C" ~ "daily"
))
user_groups = user_groups %>% select(subject_id, user_type)


scalars = left_join(scalars, user_groups)

pupils = left_join(pupils, user_groups)

scalars$user_type = factor(scalars$user_type, levels = c("non-user", "occasional", "daily"))
```


## saving scalar features

```{r}

filename = "scalars_trim.csv"

write_csv(scalars, file = here::here("data", filename))



```


# Exploring Distributions of Scalar Featurs


## Min Constriction

```{r, eval = FALSE}

ggplot(scalars, aes(x = min_constriction)) + geom_histogram() + facet_wrap(~eye)

```


## Beginning Slope

```{r, eval = FALSE}

ggplot(scalars, aes(x = beginning_slope)) + geom_histogram() + facet_wrap(~eye)

```

## Avg End Percent 

```{r, eval = FALSE}

ggplot(scalars, aes(x = avg_end_percent)) + geom_histogram() + facet_wrap(~eye) 

```

## Slope

```{r, eval = FALSE}

ggplot(scalars, aes(x = slope)) + geom_histogram() + facet_wrap(~eye)

```

## AUC 

```{r, eval = FALSE}

ggplot(scalars, aes(x = AUC)) + geom_histogram() + facet_wrap(~eye)

```
* Distributions look fairly normal

# tables


```{r}
source(here::here("analysis","helper_functions.R"))


outcome_levels = c("min_constriction", 
                   "avg_end_percent",
                   "slope",
                   "AUC",
                   "avg_percent_change_min_end",
                   "beginning_slope"
                   )

outcome_labels = c("Minimum Constriction", 
                   "Average Ending (last 30 frames)",
                   "Slope from min constrition to end of test",
                   "AUC",
                   "average Percent Change Min to End",
                   "Slope from start of test to min constriction"
                          )

tasks = c("judgement", "judgement", "judgement","judgement", "judgement", "judgement")
```

## Registration Plot 

```{R}

temp_id = "001-104post"

temp_id = "001-029post"




temp_graph = pupils %>% filter(timeid == temp_id, eye == "Right")

starting = temp_graph %>% filter(centered == "0") %>% select(frame) %>% pull()

min_constriction_frame = scalars %>% filter(timeid == temp_id, eye == "Right") %>% select(frame_min) %>% pull() + starting

## getting the slope value from the beginning of test to point of min. constriction
min_constriction_slope  = scalars %>% filter(timeid == temp_id, eye == "Right") %>% select(beginning_slope) %>% pull()

# getting the centered frame location for point of min. constriction
min_constriction_centered = scalars %>% filter(timeid == temp_id, eye == "Right") %>% select(frame_min) %>% pull() 

# Getting percent change value for point of min. constriction  (subtracted 0.4 for better placement on graph)
min_constriction_value = scalars %>% filter(timeid == temp_id, eye == "Right") %>% select(min_constriction) %>% pull() -.4

# getting the centered frame location for point of ending constriction

ending_centered = scalars %>% filter(timeid == temp_id, eye == "Right") %>% select(last_obs) %>% pull() 

# Getting percent change value for point of min. constriction  (subtracted 0.4 for better placement on graph)
ending_constriction_value = scalars %>% filter(timeid == temp_id, eye == "Right") %>% select(avg_end_percent) %>% pull() 

fit <- qgam(major_axis~ s(frame, k=25, bs="cs"), data=temp_graph, qu = 0.5)

new_data = data.frame(frame = seq(0, 600, length.out = 600))

new_data$yhat2 = predict(fit, newdata = new_data)

der_vec = NULL
der_vec2 = NULL

der_vec_max = NULL
der_vec_min = NULL

# first derivative
for (i in 1:(nrow(new_data))){
  if (i == 1){
    der_vec[i] = 0
  }
  if (i>1){
    der_vec[i] = new_data$yhat2[i+1] - new_data$yhat2[i]
  }
  if (i == nrow(new_data)) {
    der_vec[i] = 0
  }
}

####
## first derivative max
for (i in 1:(length(der_vec))){
  der_vec_max[i] = if_else(der_vec[i] >=0  & der_vec[i+1] < 0, 1,0)
}

## first derivative min 
for (i in 1:(length(der_vec))){
  der_vec_min[i] = if_else(der_vec[i] <= 0  & der_vec[i+1]  > 0, 1,0)
}


new_data$max = der_vec_max

new_data$min = der_vec_min

new_data$extremum = new_data$max + new_data$min

new_data = new_data %>% mutate(extremum = case_when(
  extremum == "1" ~ "1",
  extremum == "0" ~ "0",
  TRUE ~ "1"
)) # capturing edge points

new_data$extremum = factor(new_data$extremum)

new_data$frame = round(new_data$frame)

new_data = rename(new_data, major_axis = yhat2)
new_data = new_data %>% filter(extremum == "1") %>% select(frame, major_axis, extremum)
new_data = new_data %>% filter(frame < 550)

ID<- 1
EVENT <- rep(c("Mininum Constriction","Ending Constriction"))


centered <- c(min_constriction_centered,ending_centered)

percent_change = c(min_constriction_value+.4, ending_constriction_value )

DF.SYMBOL<-data.frame(ID,EVENT,centered, percent_change)

DF.SYMBOL$EVENT = factor(DF.SYMBOL$EVENT , levels = c("Minimum Constriction","Ending Constriction" ))



```


```{r}
# temp_id = "001-007post"

# temp_id = "001-024post"

temp_id = "001-029post"


temp = original %>% filter(timeid == temp_id, eye == "Right")

temp = temp[complete.cases(temp),] ## taking complete cases from temp data 


plot1 = ggplot(temp, aes(x = frame, y = major_axis)) + geom_point(size = 3) + 
  ylab("Major Axis Size") + 
  # ggtitle("A") + 
  theme(axis.title = element_text(size = 30), axis.text = element_text(size = 30))+ 
    theme(plot.title = element_text(size = 30, face = "bold")) +
  scale_x_continuous(name="frame", breaks= seq(0, 600, 100)) + 
  xlim(c(0, 610))
ggsave(file="3A.png")

   

quantile_gam_left = qgam(major_axis~ s(frame, k=25, bs="cs"),
  										data = temp,
  										qu = 0.5)
  
p <- predict(quantile_gam_left, type = "link", se.fit = TRUE)# predicted values
  
upr <- p$fit + (6*p$se.fit) # upper threshold
lwr <- p$fit - (6*p$se.fit) # lower threshold

majors = temp$major_axis # getting vector from temp data frame to check for outliers
new_vec = NULL # initiating vec to keep track of whether or not point is within SE's
  
for (i in 1:length(p$fit)){
  new_vec[i] = if_else(majors[i] < upr[i] & majors[i] > lwr[i], 1, 0) # checks whether point is within x SE's
    }
  
temp$outliers = new_vec # attaches outlier identifying vec to temp data
temp$outliers = factor(temp$outliers, labels = c("Yes", "No"))

temp$predicted = p$fit
temp$upr = upr
temp$lwr = lwr

plot2= ggplot(temp, aes(x = frame, y = major_axis)) + geom_point(aes(colour = temp$outliers)) + geom_line(aes(x = temp$frame, y = temp$upr)) + geom_line(aes(x = temp$frame, y = temp$lwr)) + 
  ylab("Major Axis Size") + 
  # ggtitle("B") + 
  theme(axis.title = element_text(size = 30), legend.text=element_text(size=20), legend.title=element_text(size=20), legend.position = c(0.85, 0.25), axis.text = element_text(size = 30))+ 
  guides(colour = guide_legend(title = "Outlier")) + 
    theme(plot.title = element_text(size = 30, face = "bold")) +
  scale_x_continuous(name="frame", breaks= seq(0, 600, 100))+ 
  xlim(c(0, 610))
ggsave(file="3B.png")

cleaned = temp %>% filter(outliers == "No")


fit <- qgam(major_axis~ s(frame, k=35, bs="cs"), data=cleaned, qu = 0.5)

new_data2 = data.frame(frame = seq(0, max(temp$frame), length.out = nrow(cleaned %>% filter(outliers == "No"))))

new_data2$yhat2 = predict(fit, newdata = new_data2)


plot3 = ggplot(cleaned, aes(x = frame, y = major_axis)) + geom_point(size = 3) + geom_line(aes(x =new_data2$frame, y = new_data2$yhat2)) + 
  ylab("Major Axis Size") + 
  # ggtitle("C") + 
  theme(axis.title = element_text(size = 30), axis.text = element_text(size = 30))+ 
    theme(plot.title = element_text(size = 30, face = "bold")) +
  scale_x_continuous(name="frame", breaks= seq(0, 600, 100))+ 
  ylim(c(90, 115))+ 
  xlim(c(0, 610))
ggsave(file="3C.png")


plot4 = ggplot(temp_graph, aes(x = frame, y = yhat2 )) + geom_line() + geom_vline(aes(xintercept=min_constriction_frame, colour = "blue")) +
  geom_vline(aes(xintercept= starting, colour = "red")) +
  geom_point(data = new_data, aes(x = frame, y = major_axis, fill = extremum, shape = extremum), size = 6) + 
  ylab("Major Axis Size") + 
  # ggtitle("D") + 
  theme(axis.title = element_text(size = 30), legend.text=element_text(size=15), legend.title=element_text(size=15), legend.position = c(0.75, 0.15), axis.text = element_text(size = 30))+ 
  guides(shape = guide_legend(title = element_blank(), order = 1), fill="none", colour = guide_legend(title = "Steepest Decrease")) + 
  scale_shape_discrete(labels = "Relative Extrema") + 
  scale_colour_discrete(labels = c("Minimum", "Maximum")) + 
    theme(plot.title = element_text(size = 30, face = "bold")) +
  scale_x_continuous(name="frame", breaks= seq(0, 600, 100)) + 
  ylim(c(90, 115))+ 
  xlim(c(0, 610))
ggsave(file="3D.png")

plot5 = ggplot(temp_graph, aes(x = centered, y = yhat2 )) + geom_line() + geom_vline(aes(xintercept=0),linetype="dotted") + 
  # ggtitle("E") + 
  ylab("Major Axis Size") + 
  xlab("frame") + 
  theme(axis.title = element_text(size = 30), legend.text=element_text(size=30), legend.title=element_text(size=30), legend.position = c(0.7, 0.25), axis.text = element_text(size = 30))  + 
    theme(plot.title = element_text(size = 30, face = "bold")) + 
  ylim(c(90, 115))+
  scale_x_continuous(name="frame", breaks= seq(0, 600, 100))+ 
  xlim(c(0, 610))
ggsave(file="3E.png")

# 
# plot3 = ggplot(pupils %>% filter(centered >= 0, eye == "Right"), aes(x = centered, y = percent_change, fill = timeid)) + geom_line(alpha = 0.2)  + theme(legend.position = "none") + ggtitle("C") + ylab("Percent Change from Baseline") + theme(plot.title = element_text(size = 20, face = "bold")) +
#   theme(plot.title = element_text(hjust = 0.5))


plot6 = ggplot(temp_graph %>% filter(centered >= 0, eye == "Right"), aes(x = centered, y = percent_change, fill = timeid)) + geom_line()  + theme(legend.position = "none") +
  # ggtitle("F") + 
  ylab("Percent Change from Baseline") + 
  xlab("frame") +
  theme(axis.title = element_text(size = 30), legend.text=element_text(size=30), legend.title=element_text(size=30), legend.position = c(0.7, 0.25), axis.text = element_text(size = 30))  + 
    theme(plot.title = element_text(size = 30, face = "bold"))+
  scale_x_continuous(name="frame", breaks= seq(0, 605, 100))
ggsave(file="3F.png")

ggarrange(plot1, plot2, plot3, plot4, plot5, plot6, ncol = 3, nrow = 2)

# ggsave(file="registration_fig5.png")


```

```{R}
## Breaking down above plots into ind. plots with slight modification for thesis proposal slides. 
plot1 = ggplot(temp, aes(x = frame, y = major_axis)) + geom_point(size = 3) + 
  ylab("Major Axis Size") + 
  ggtitle("Estimated Major Axis") + 
  theme(axis.title = element_text(size = 30), axis.text = element_text(size = 30))+ 
    theme(plot.title = element_text(size = 30, face = "bold")) +
  scale_x_continuous(name="frame", breaks= seq(0, 610, 100)) +
  theme(plot.title = element_text(hjust = 0.5))

plot1
ggsave(file="/Users/benjaminsteinhart/Desktop/image_seg/reports/figures_thesis/major_output_original.png")

plot2= ggplot(temp, aes(x = frame, y = major_axis)) + geom_point(aes(colour = temp$outliers), size = 3) + geom_line(aes(x = temp$frame, y = temp$upr), size = 1.3) + geom_line(aes(x = temp$frame, y = temp$lwr), size = 1.3) + 
  ylab("Major Axis Size") + 
  ggtitle("Outliers") + 
  theme(axis.title = element_text(size = 30), legend.text=element_text(size=20), legend.title=element_text(size=20), legend.position = c(0.85, 0.25), axis.text = element_text(size = 30))+ 
  guides(colour = guide_legend(title = "Outlier")) + 
    theme(plot.title = element_text(size = 30, face = "bold")) +
  scale_x_continuous(name="frame", breaks= seq(0, 610, 100))  +
  theme(plot.title = element_text(hjust = 0.5))

plot3 = ggplot(cleaned, aes(x = frame, y = major_axis)) + geom_point(size=3) + geom_line(aes(x =new_data2$frame, y = new_data2$yhat2), color = "red", size =1.2) + 
  ylab("Major Axis Size") + 
  ggtitle("Cleaned and Refit") + 
  theme(axis.title = element_text(size = 30), axis.text = element_text(size = 30))+ 
    theme(plot.title = element_text(size = 30, face = "bold")) +
  scale_x_continuous(name="frame", breaks= seq(0, 610, 100))+ 
  ylim(c(90, 115)) +
  theme(plot.title = element_text(hjust = 0.5))

ggarrange(plot1, plot2, plot3, ncol = 3)

ggsave(file="/Users/benjaminsteinhart/Desktop/image_seg/reports/figures_thesis/major_axis_cleaned.png")
```

```{r}
## ACF figure thesis 

library(tseries) # for autocorrelation function 
x = temp %>% select(major_axis) %>% pull()
x =x[!is.na(x)]
acf1 = round(acf(x, pl = FALSE)$acf[2],3)


x = cleaned %>% select(major_axis) %>% pull()
x =x[!is.na(x)]
acf2 = round(acf(x, pl = FALSE)$acf[2],3)


plot1 = ggplot(temp, aes(x = frame, y = major_axis)) + geom_point(size = 3) + 
  ylab("Major Axis Size") + 
  ggtitle(paste0("Original AC: ", as.character(acf1))) + 
  theme(axis.title = element_text(size = 30), axis.text = element_text(size = 30))+ 
    theme(plot.title = element_text(size = 30, face = "bold")) +
  scale_x_continuous(name="frame", breaks= seq(0, 610, 100)) +
  theme(plot.title = element_text(hjust = 0.5))



plot3 = ggplot(cleaned, aes(x = frame, y = major_axis)) + geom_point(size = 3) + geom_line(aes(x =new_data2$frame, y = new_data2$yhat2), colour = "red", size = 1.2) + 
  ylab("Major Axis Size") + 
  ggtitle(paste0("Cleaned AC: ", as.character(acf2))) + 
  theme(axis.title = element_text(size = 30), axis.text = element_text(size = 30))+ 
    theme(plot.title = element_text(size = 30, face = "bold")) +
  scale_x_continuous(name="frame", breaks= seq(0, 610, 100))+ 
  ylim(c(90, 115)) +
  theme(plot.title = element_text(hjust = 0.5))

ggarrange(plot1, plot3, ncol = 2)

ggsave(file="/Users/benjaminsteinhart/Desktop/image_seg/reports/figures_thesis/acf.png")
```

```{r}
##### PLot for beginning and ending of test 

temp_id = "001-053post"



temp_graph = pupils %>% filter(timeid == temp_id, eye == "Right")

starting = temp_graph %>% filter(centered == "0") %>% select(frame) %>% pull()

min_constriction_frame = scalars %>% filter(timeid == temp_id, eye == "Right") %>% select(frame_min) %>% pull() + starting

## getting the slope value from the beginning of test to point of min. constriction
min_constriction_slope  = scalars %>% filter(timeid == temp_id, eye == "Right") %>% select(beginning_slope) %>% pull()

# getting the centered frame location for point of min. constriction
min_constriction_centered = scalars %>% filter(timeid == temp_id, eye == "Right") %>% select(frame_min) %>% pull() 

# Getting percent change value for point of min. constriction  (subtracted 0.4 for better placement on graph)
min_constriction_value = scalars %>% filter(timeid == temp_id, eye == "Right") %>% select(min_constriction) %>% pull() -.4

# getting the centered frame location for point of ending constriction

ending_centered = scalars %>% filter(timeid == temp_id, eye == "Right") %>% select(last_obs) %>% pull() 

# Getting percent change value for point of min. constriction  (subtracted 0.4 for better placement on graph)
ending_constriction_value = scalars %>% filter(timeid == temp_id, eye == "Right") %>% select(avg_end_percent) %>% pull() 

fit <- qgam(major_axis~ s(frame, k=25, bs="cs"), data=temp_graph, qu = 0.5)

new_data = data.frame(frame = seq(0, 600, length.out = 600))

new_data$yhat2 = predict(fit, newdata = new_data)

der_vec = NULL
der_vec2 = NULL

der_vec_max = NULL
der_vec_min = NULL

# first derivative
for (i in 1:(nrow(new_data))){
  if (i == 1){
    der_vec[i] = 0
  }
  if (i>1){
    der_vec[i] = new_data$yhat2[i+1] - new_data$yhat2[i]
  }
  if (i == nrow(new_data)) {
    der_vec[i] = 0
  }
}

####
## first derivative max
for (i in 1:(length(der_vec))){
  der_vec_max[i] = if_else(der_vec[i] >=0  & der_vec[i+1] < 0, 1,0)
}

## first derivative min 
for (i in 1:(length(der_vec))){
  der_vec_min[i] = if_else(der_vec[i] <= 0  & der_vec[i+1]  > 0, 1,0)
}


new_data$max = der_vec_max

new_data$min = der_vec_min

new_data$extremum = new_data$max + new_data$min

new_data = new_data %>% mutate(extremum = case_when(
  extremum == "1" ~ "1",
  extremum == "0" ~ "0",
  TRUE ~ "1"
)) # capturing edge points

new_data$extremum = factor(new_data$extremum)

new_data$frame = round(new_data$frame)

new_data = rename(new_data, major_axis = yhat2)
new_data = new_data %>% filter(extremum == "1") %>% select(frame, major_axis, extremum)
new_data = new_data %>% filter(frame < 550)

ID<- 1
EVENT <- rep(c("Mininum Constriction","Ending Constriction"))


centered <- c(min_constriction_centered,ending_centered)

percent_change = c(min_constriction_value+.4, ending_constriction_value )

DF.SYMBOL<-data.frame(ID,EVENT,centered, percent_change)

DF.SYMBOL$EVENT = factor(DF.SYMBOL$EVENT , levels = c("Minimum Constriction","Ending Constriction" ))



temp = original %>% filter(timeid == temp_id, eye == "Right")

temp = temp[complete.cases(temp),] ## taking complete cases from temp data 


plot1 = ggplot(temp, aes(x = frame, y = major_axis)) + geom_point() + 
  ylab("Major Axis Size") + 
  ggtitle("A") + 
  theme(axis.title = element_text(size = 30), axis.text = element_text(size = 30))+ 
    theme(plot.title = element_text(size = 30, face = "bold")) +
  scale_x_continuous(name="frame", breaks= seq(0, 600, 100))
   

quantile_gam_left = qgam(major_axis~ s(frame, k=25, bs="cs"),
  										data = temp,
  										qu = 0.5)
  
p <- predict(quantile_gam_left, type = "link", se.fit = TRUE)# predicted values
  
upr <- p$fit + (6*p$se.fit) # upper threshold
lwr <- p$fit - (6*p$se.fit) # lower threshold

majors = temp$major_axis # getting vector from temp data frame to check for outliers
new_vec = NULL # initiating vec to keep track of whether or not point is within SE's
  
for (i in 1:length(p$fit)){
  new_vec[i] = if_else(majors[i] < upr[i] & majors[i] > lwr[i], 1, 0) # checks whether point is within x SE's
    }
  
temp$outliers = new_vec # attaches outlier identifying vec to temp data
temp$outliers = factor(temp$outliers, labels = c("Yes", "No"))

temp$predicted = p$fit
temp$upr = upr
temp$lwr = lwr

plot2= ggplot(temp, aes(x = frame, y = major_axis)) + geom_point(aes(colour = temp$outliers)) + geom_line(aes(x = temp$frame, y = temp$upr)) + geom_line(aes(x = temp$frame, y = temp$lwr)) + 
  ylab("Major Axis Size") + 
  ggtitle("B") + 
  theme(axis.title = element_text(size = 30), legend.text=element_text(size=20), legend.title=element_text(size=20), legend.position = c(0.85, 0.25), axis.text = element_text(size = 30))+ 
  guides(colour = guide_legend(title = "Outlier")) + 
    theme(plot.title = element_text(size = 30, face = "bold")) +
  scale_x_continuous(name="frame", breaks= seq(0, 600, 100))

cleaned = temp %>% filter(outliers == "No")


fit <- qgam(major_axis~ s(frame, k=35, bs="cs"), data=cleaned, qu = 0.5)

new_data2 = data.frame(frame = seq(0, max(temp$frame), length.out = nrow(cleaned %>% filter(outliers == "No"))))

new_data2$yhat2 = predict(fit, newdata = new_data2)


plot3 = ggplot(cleaned, aes(x = frame, y = major_axis)) + geom_point() + geom_line(aes(x =new_data2$frame, y = new_data2$yhat2)) + 
  ylab("Major Axis Size") + 
  ggtitle("Post Cleaning") + 
  theme(axis.title = element_text(size = 30), axis.text = element_text(size = 30))+ 
    theme(plot.title = element_text(size = 30, face = "bold")) +
  scale_x_continuous(name="frame", breaks= seq(0, 600, 100))  +
  theme(plot.title = element_text(hjust = 0.5))


plot4 = ggplot(temp_graph, aes(x = frame, y = yhat2 )) + geom_line() + geom_vline(aes(xintercept=min_constriction_frame, colour = "blue")) +
  geom_vline(aes(xintercept= starting, colour = "red")) +
  geom_point(data = new_data, aes(x = frame, y = major_axis, fill = extremum, shape = extremum), size = 6) + 
  ylab("Major Axis Size") + 
  ggtitle("Registration Steps") + 
  theme(axis.title = element_text(size = 30), legend.text=element_text(size=15), legend.title=element_text(size=15), legend.position = c(0.75, 0.15), axis.text = element_text(size = 30))+ 
  guides(shape = guide_legend(title = element_blank(), order = 1), fill="none", colour = guide_legend(title = "Steepest Decrease")) + 
  scale_shape_discrete(labels = "Relative Extrema") + 
  scale_colour_discrete(labels = c("Minimum", "Maximum")) + 
    theme(plot.title = element_text(size = 30, face = "bold")) +
  scale_x_continuous(name="frame", breaks= seq(0, 600, 100))   +
  theme(plot.title = element_text(hjust = 0.5))

plot5 = ggplot(temp_graph, aes(x = centered, y = yhat2 )) + geom_line() + geom_vline(aes(xintercept=0),linetype="dotted") + ggtitle("Post Registration") + ylab("Major Axis Size") + 
  xlab("frame") + 
  theme(axis.title = element_text(size = 30), legend.text=element_text(size=30), legend.title=element_text(size=30), legend.position = c(0.7, 0.25), axis.text = element_text(size = 30))  + 
    theme(plot.title = element_text(size = 30, face = "bold")) + 
  scale_x_continuous(name="frame", breaks= seq(0, 600, 100))  +
  theme(plot.title = element_text(hjust = 0.5))


plot6 = ggplot(temp_graph %>% filter(centered >= 0, eye == "Right"), aes(x = centered, y = percent_change, fill = timeid)) + geom_line()  + theme(legend.position = "none") + ggtitle("Final Trajectory") + ylab("Percent Change from Baseline") + 
  xlab("frame") +
  theme(axis.title = element_text(size = 30), legend.text=element_text(size=30), legend.title=element_text(size=30), legend.position = c(0.7, 0.25), axis.text = element_text(size = 30))  + 
    theme(plot.title = element_text(size = 30, face = "bold"))+
  scale_x_continuous(name="frame", breaks= seq(0, 600, 100))  +
  theme(plot.title = element_text(hjust = 0.5))

ggarrange(plot3, plot4, plot5, plot6, ncol = 2, nrow = 2)

ggsave(file="/Users/benjaminsteinhart/Desktop/image_seg/reports/figures_thesis/registering.png")
```




# Notation Figure 

## Overview Plot - 2 features

```{r, eval = FALSE}


temp_id = "001-029post"

temp_graph = pupils %>% filter(timeid == temp_id, eye == "Right")

starting = temp_graph %>% filter(centered == "0") %>% select(frame) %>% pull()

min_constriction_frame = scalars %>% filter(timeid == temp_id, eye == "Right") %>% select(frame_min) %>% pull() + starting

## getting the slope value from the beginning of test to point of min. constriction
min_constriction_slope  = scalars %>% filter(timeid == temp_id, eye == "Right") %>% select(beginning_slope) %>% pull()

# getting the centered frame location for point of min. constriction
min_constriction_centered = scalars %>% filter(timeid == temp_id, eye == "Right") %>% select(frame_min) %>% pull() 

# Getting percent change value for point of min. constriction  (subtracted 0.4 for better placement on graph)
min_constriction_value = scalars %>% filter(timeid == temp_id, eye == "Right") %>% select(min_constriction) %>% pull() -.4

# getting the centered frame location for point of ending constriction

ending_centered = scalars %>% filter(timeid == temp_id, eye == "Right") %>% select(last_obs) %>% pull() 

# Getting percent change value for point of min. constriction  (subtracted 0.4 for better placement on graph)
ending_constriction_value = scalars %>% filter(timeid == temp_id, eye == "Right") %>% select(avg_end_percent) %>% pull() 

fit <- qgam(major_axis~ s(frame, k=25, bs="cs"), data=temp_graph, qu = 0.5)

new_data = data.frame(frame = seq(0, 600, length.out = 600))

new_data$yhat2 = predict(fit, newdata = new_data)

der_vec = NULL
der_vec2 = NULL

der_vec_max = NULL
der_vec_min = NULL

# first derivative
for (i in 1:(nrow(new_data))){
  if (i == 1){
    der_vec[i] = 0
  }
  if (i>1){
    der_vec[i] = new_data$yhat2[i+1] - new_data$yhat2[i]
  }
  if (i == nrow(new_data)) {
    der_vec[i] = 0
  }
}

####
## first derivative max
for (i in 1:(length(der_vec))){
  der_vec_max[i] = if_else(der_vec[i] >=0  & der_vec[i+1] < 0, 1,0)
}

## first derivative min 
for (i in 1:(length(der_vec))){
  der_vec_min[i] = if_else(der_vec[i] <= 0  & der_vec[i+1]  > 0, 1,0)
}


new_data$max = der_vec_max

new_data$min = der_vec_min

new_data$extremum = new_data$max + new_data$min

new_data = new_data %>% mutate(extremum = case_when(
  extremum == "1" ~ "1",
  extremum == "0" ~ "0",
  TRUE ~ "1"
)) # capturing edge points

new_data$extremum = factor(new_data$extremum)

new_data$frame = round(new_data$frame)

new_data = rename(new_data, major_axis = yhat2)
new_data = new_data %>% filter(extremum == "1") %>% select(frame, major_axis, extremum)
new_data = new_data %>% filter(frame < 550)

ID<- 1
EVENT <- rep(c("Minimum Constriction","Ending Constriction"))


centered <- c(min_constriction_centered,ending_centered)

percent_change = c(min_constriction_value+.4, ending_constriction_value )

DF.SYMBOL<-data.frame(ID,EVENT,centered, percent_change)

DF.SYMBOL$EVENT = factor(DF.SYMBOL$EVENT , levels = c("Minimum Constriction","Ending Constriction" ))



plot1 = ggplot(original %>% filter(timeid == temp_id, eye == "Right"), aes(x = frame, y = major_axis)) + geom_point()+
  ylab("Major Axis Size") + 
  xlab("Frame")+ 
  theme(axis.title = element_text(size = 55),  axis.text = element_text(size = 25))+
  scale_x_continuous(name="frame", breaks= seq(0, 600, 100)) + ylim(c(50, 125))

plot2 = ggplot(pupils %>% filter(timeid == temp_id, eye == "Right"), aes(x = frame, y = yhat2)) + geom_point()+
  ylab("Major Axis Size") + 
  xlab("Frame")+ 
  theme(axis.title = element_text(size = 55),  axis.text = element_text(size = 25)) +
  scale_x_continuous(name="frame", breaks= seq(0, 600, 100))+ ylim(c(50, 125))


temp_graph = temp_graph %>% filter(centered>=0)

plot3 = ggplot(temp_graph , aes(x = centered, y = percent_change, fill = timeid)) + geom_line()  +
  ylab("Percent Change from Baseline") + 
  xlab("frame") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  geom_ribbon(aes(x=temp_graph$centered, ymax=0, colour = "AUC"), ymin=temp_graph$percent_change,alpha=0.3) + 
  geom_abline(aes(slope=min_constriction_slope[1], intercept=0, colour="Slope to Min. Constriction "), size=3) +
  geom_point(data = DF.SYMBOL, aes(x = centered, y = percent_change, fill = EVENT, shape = EVENT), size = 8) + guides(shape = guide_legend(title = "Scalar Outcomes", order = 1), fill="none", colour = guide_legend(title = element_blank())) + 
  theme(legend.position="right") + 
  theme(legend.margin = margin(-0.5,0,0,0, unit="cm")) + 
  theme(axis.title = element_text(size = 55), legend.text=element_text(size=20), legend.title=element_text(size=25), legend.position = c(0.6, 0.25), axis.text = element_text(size = 25)) 


ggarrange(plot1, plot2, plot3, ncol = 3)

# ggsave(file="overview_mult.png")



```


## Overview Plot - 2 features

```{r, eval = FALSE}

ID<- 1
EVENT <- rep(c("Percent Light Reflex"))

centered <- c(min_constriction_centered)

percent_change = c(min_constriction_value+.4)

DF.SYMBOL<-data.frame(ID,EVENT,centered, percent_change)

DF.SYMBOL$EVENT = factor(DF.SYMBOL$EVENT , levels = c("Percent Light Reflex"))

# ### Blink Rate
# ID<- 1
# EVENT <- rep(c("Blinking"))
# 
# centered <- c(19, 100, 225)
# 
# blinking = c(-4, -11.8, -8.723)
# 
# DF.SYMBOL2<-data.frame(ID,EVENT,centered, blinking)
# 
# DF.SYMBOL2$EVENT = factor(DF.SYMBOL2$EVENT , levels = c("Blinking"))



###### Plots
# plot1 = ggplot(original %>% filter(timeid == temp_id, eye == "Right"), aes(x = frame, y = major_axis)) + geom_point()+
#   ylab("Major Axis Size") + 
#   xlab("Frame")+ 
#   theme(axis.title = element_text(size = 55),  axis.text = element_text(size = 25))+
#   scale_x_continuous(name="frame", breaks= seq(0, 600, 100)) + ylim(c(50, 125))
# 
# plot2 = ggplot(pupils %>% filter(timeid == temp_id, eye == "Right"), aes(x = frame, y = yhat2)) + geom_point()+
#   ylab("Major Axis Size") + 
#   xlab("Frame")+ 
#   theme(axis.title = element_text(size = 55),  axis.text = element_text(size = 25)) +
#   scale_x_continuous(name="frame", breaks= seq(0, 600, 100))+ ylim(c(50, 125))
# 
# 
# temp_graph = temp_graph %>% filter(centered>=0)
# 
# plot3 = ggplot(temp_graph , aes(x = centered, y = percent_change, fill = timeid)) + geom_line()  +
#   ylab("Percent Change from Baseline") + 
#   xlab("frame") + 
#   theme(plot.title = element_text(hjust = 0.5)) + 
#   geom_ribbon(aes(x=temp_graph$centered, ymax=0, colour = "Rebound Dilation"), ymin=temp_graph$percent_change,alpha=0.3) +
#   geom_point(data = DF.SYMBOL, aes(x = centered, y = percent_change, fill = EVENT, shape = EVENT), size = 8) + guides(shape = guide_legend(title = "Scalar Outcomes", order = 1), fill="none", colour = guide_legend(title = element_blank())) + 
#   theme(legend.position="right") + 
#   theme(legend.margin = margin(-0.5,0,0,0, unit="cm")) + 
#   theme(axis.title = element_text(size = 55), legend.text=element_text(size=20), legend.title=element_text(size=25), legend.position = c(0.6, 0.25), axis.text = element_text(size = 25)) 
# 
# ggarrange(plot1, plot2, plot3, ncol = 3)
# 
# ggsave(file="overview_mult.png")
# 


ggplot(original %>% filter(timeid == temp_id, eye == "Right"), aes(x = frame, y = major_axis)) + geom_point(size = 2)+
  ylab("Major Axis Size") + 
  xlab("Frame")+ 
  theme(axis.title = element_text(size = 20),  axis.text = element_text(size = 15))+
  scale_x_continuous(name="frame", breaks= seq(0, 600, 100)) + ylim(c(50, 125))

ggsave(file="estimates_seg_pipe.png")


ggplot(pupils %>% filter(timeid == temp_id, eye == "Right"), aes(x = frame, y = yhat2)) + geom_point(size = 2 )+
  ylab("Major Axis Size") + 
  xlab("Frame")+ 
  theme(axis.title = element_text(size = 20),  axis.text = element_text(size = 15)) +
  scale_x_continuous(name="frame", breaks= seq(0, 600, 100))+ ylim(c(50, 125))

ggsave(file="estimates_qgam.png")

ribbon_dat = temp_graph %>% filter(centered>min_constriction_centered)

ggplot(temp_graph %>% filter(centered >=0), aes(x = centered, y = percent_change, fill = timeid)) + geom_line()  +
  ylab("Percent Change from Baseline") + 
  xlab("frame") + 
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_ribbon(
    data = ribbon_dat,
    mapping = aes(ymin = percent_change, ymax = 0, colour = "Rebound Dilation"), alpha = 0.3) +
  geom_point(data = DF.SYMBOL, aes(x = centered, y = percent_change, fill = EVENT, shape = EVENT), size = 4) +
  guides(shape = guide_legend(title = "Scalar Outcomes", order = 1), fill="none", colour = guide_legend(title = element_blank())) +
  theme(legend.position="right") +
  theme(legend.margin = margin(-0.5,0,0,0, unit="cm")) +
  theme(axis.title = element_text(size = 18), legend.text=element_text(size=16), legend.title=element_text(size=16), legend.position = c(0.77, 0.15), axis.text = element_text(size = 15)) +
  theme(legend.title.align=0.5)

ggsave(file="2scalarfeature.png")


```

# Overview

The purpose of this document is to provide primary analysis of Ocular Data

* outcomes tested using linear regression
* `p.overall` is the ANOVA p-value

## Updates from last time


* *Ranked judgement*: Numeric ranking based on success ratio and then time to complete task. Highest ranking given to those with 100% success ratio. Within that grouping, best ranking given to participant who completed the time the fastest. Best ranking is given to participant with highest success ratio and lowest time to complete task. 

## Unadjusted analysis

For each of the different outcomes and at each time point (pre and post) we run a regression model with user group as the main covariate of interest. Not adjusted for confounders.  

### Pre Event

Below are the group means, unadjusted at the PRE even. For each user group shown are mean (95% CI).

```{r}
scalars = rename(scalars, prepost = time)

vars = scalars  %>%
  select(-subject_id, -user_type, -prepost, -timeid, -eye, -centered, -last_obs, -frame_min, - duration
         ) %>%
  names()


pre_data = scalars %>%
  filter(prepost == "pre2", eye == "Left")



map_dfr(vars, make_mean_row, dat = pre_data) %>%
    mutate(outcome = factor(outcome, 
                          levels = outcome_levels,
                          labels = outcome_labels)) %>%
  mutate(task = tasks) %>% 
  select(outcome, task, everything()) %>%
  knitr::kable(digits = 1)

```


### Post Event

Below are the group means, unadjusted at the POST even. For each user group shown are mean (95% CI).

```{r}

vars = scalars  %>%
  select(-subject_id, -user_type, -prepost, -timeid, -eye, -centered, -last_obs, -frame_min, - duration
         ) %>%
  names()


pre_data = scalars %>%
  filter(prepost == "post", eye == "Left")



map_dfr(vars, make_mean_row, dat = pre_data) %>%
    mutate(outcome = factor(outcome, 
                          levels = outcome_levels,
                          labels = outcome_labels)) %>%
  mutate(task = tasks) %>% 
  select(outcome, task, everything()) %>%
  knitr::kable(digits = 1)
```
* Slope being higher at the post event for non-users is peculiar; Means they likely had constriction and then returned to higher baselines than occasional and daily users. Probably opposite of what would be expected. 


## Difference Left

```{r}

dif_data = scalars %>% filter(eye == "Left") %>% select( prepost,  subject_id, user_type, min_constriction, avg_end_percent, avg_percent_change_min_end, slope, AUC, beginning_slope)

dif_data$prepost = factor(dif_data$prepost)

dif_data = dif_data %>% pivot_wider(id_cols = c(subject_id, user_type) ,names_from = prepost, values_from = min_constriction:beginning_slope)

difference_function = function(data, pre_var, post_var, dif_name){
  var1 <- enquo(pre_var)
  var2 <- enquo(post_var)
  temp= data
  temp = data %>% group_by(subject_id) %>%  mutate(temp_variable = (!!var2 - !!var1)) %>% ungroup()
  names(temp)[names(temp)== "temp_variable"] = dif_name
  return(temp)
}

# judgment variables *****
## PREMATURE
#difference in min constriction
dif_data = difference_function(dif_data, min_constriction_pre2, min_constriction_post, "min_constriction_difference") 


#difference in avg_percent_change_min_end
dif_data = difference_function(dif_data, avg_percent_change_min_end_pre2, avg_percent_change_min_end_post, "avg_percent_change_min_end_difference") 

#difference in avg_end_percent
dif_data = difference_function(dif_data, avg_end_percent_pre2, avg_end_percent_post, "avg_end_percent_difference")

#difference in slope
dif_data = difference_function(dif_data, slope_pre2, slope_post, "slope_difference")

#difference in AUC
dif_data = difference_function(dif_data, AUC_pre2, AUC_post, "AUC_difference")

#difference in AUC
dif_data = difference_function(dif_data, beginning_slope_pre2, beginning_slope_post, "beginning_slope_difference")

dif_data = dif_data %>% select(subject_id, user_type, contains("difference")) 

```



```{r}

vars = dif_data %>%
  select(-subject_id, -user_type) %>%
  names()

map_dfr(vars, make_mean_row, dat = dif_data) %>%
  mutate(outcome = str_remove(outcome, "_difference"))%>%
    mutate(outcome = factor(outcome, 
                          levels = outcome_levels,
                          labels = outcome_labels)) %>%
  mutate(task = tasks) %>%
  select(outcome, task, everything()) %>%
  knitr::kable(digits = 1)

```


## Difference Right

```{r}

dif_data = scalars %>% filter(eye == "Right") %>% select( prepost,  subject_id, user_type, min_constriction, avg_end_percent, avg_percent_change_min_end, slope, AUC, beginning_slope)

dif_data$prepost = factor(dif_data$prepost)

dif_data = dif_data %>% pivot_wider(id_cols = c(subject_id, user_type) ,names_from = prepost, values_from = min_constriction:beginning_slope)

difference_function = function(data, pre_var, post_var, dif_name){
  var1 <- enquo(pre_var)
  var2 <- enquo(post_var)
  temp= data
  temp = data %>% group_by(subject_id) %>%  mutate(temp_variable = (!!var2 - !!var1)) %>% ungroup()
  names(temp)[names(temp)== "temp_variable"] = dif_name
  return(temp)
}

# judgment variables *****
## PREMATURE
#difference in min constriction
dif_data = difference_function(dif_data, min_constriction_pre2, min_constriction_post, "min_constriction_difference") 


#difference in avg_percent_change_min_end
dif_data = difference_function(dif_data, avg_percent_change_min_end_pre2, avg_percent_change_min_end_post, "avg_percent_change_min_end_difference") 

#difference in avg_end_percent
dif_data = difference_function(dif_data, avg_end_percent_pre2, avg_end_percent_post, "avg_end_percent_difference")

#difference in slope
dif_data = difference_function(dif_data, slope_pre2, slope_post, "slope_difference")

#difference in AUC
dif_data = difference_function(dif_data, AUC_pre2, AUC_post, "AUC_difference")

#difference in AUC
dif_data = difference_function(dif_data, beginning_slope_pre2, beginning_slope_post, "beginning_slope_difference")

dif_data = dif_data %>% select(subject_id, user_type, contains("difference")) 

```

```{r}

vars = dif_data %>%
  select(-subject_id, -user_type) %>%
  names()

map_dfr(vars, make_mean_row, dat = dif_data) %>%
  mutate(outcome = str_remove(outcome, "_difference"))%>%
    mutate(outcome = factor(outcome, 
                          levels = outcome_levels,
                          labels = outcome_labels)) %>%
  mutate(task = tasks) %>%
  select(outcome, task, everything()) %>%
  knitr::kable(digits = 1)

```

## Graph of pupil projections

```{r, eval = FALSE}

prac = pupils  %>%  filter(centered >=0, eye == "Left", centered < 450, time == "post")

prac$timeid = factor(prac$timeid)

prac = prac %>% arrange(timeid)

 
 MAPPING <- prac %>% distinct(user_type,timeid)
MAPPING$user_type = factor(MAPPING$user_type)
RS_COLS =  c("grey40", "grey40", "grey40")
RS_COLS = RS_COLS[1:n_distinct(MAPPING$user_type)]
names(RS_COLS) = unique(MAPPING$user_type)
PLOT_COLS = RS_COLS[MAPPING$user_type]
names(PLOT_COLS) = MAPPING$timeid
 
ggplot(prac ,mapping=aes(x=centered, y=percent_change)) + 
  geom_line(size=0.1 ,aes(group = timeid)) + theme_bw() + 
    scale_color_manual(values = PLOT_COLS) +
  theme(legend.position = "none") +
  ylab("Percent Change from Baseline") + 
  xlab("Frame") + 
  theme(axis.title = element_text(size = 55), axis.text = element_text(size = 50)) + 
geom_smooth(data = prac %>% filter(user_type == "non-user"), aes(x = centered, y = percent_change), method = "lm", formula = y ~ splines::bs(x, 20), se = F, color = "red", size = 3) + 
  geom_smooth(data = prac %>% filter(user_type == "occasional"), aes(x = centered, y = percent_change), method = "lm", formula = y ~ splines::bs(x, 20), se = F, color = "blue", size = 3 ) + 
  geom_smooth(data = prac %>% filter(user_type == "daily"), aes(x = centered, y = percent_change), method = "lm", formula = y ~ splines::bs(x, 20), se = F, color = "green", size = 3) 
 
ggsave(file="full_pupil_projections_fin.png")

 # red non user 
 # blue occasional
 # daily is green 
 

```


# Gee models

```{r}

library(gee)
library("geepack")

scalars$prepost = factor(scalars$prepost, levels = c("pre2", "post"))
scalars$eye = factor(scalars$eye, levels = c("Left", "Right"))

practice = scalars %>% select(subject_id, prepost, eye, min_constriction, AUC, slope, avg_percent_change_min_end,  user_type)

min_gee <- geeglm(min_constriction ~ eye + prepost*user_type,
               data = practice, 
               id = factor(subject_id), 
               family = gaussian,
               corstr = "independence")


auc_gee <- geeglm(AUC ~ eye + prepost*user_type,
               data = practice, 
               id = factor(subject_id), 
               family = gaussian,
               corstr = "independence")

```


# Group means 

```{R}
# Int + right + post + occasional + daily + post*occasional + post*daily

pre_non = c(1, 0, 0, 0, 0, 0, 0)
pre_occ = c(1, 0, 0, 1, 0, 0, 0)
pre_daily = c(1, 0, 0, 0, 1, 0, 0)

# Int + right + post + occasional + daily + post*occasional + post*daily
post_non = c(1, 0, 1, 0, 0, 0, 0)
post_occ = c(1, 0, 1, 1, 0, 1, 0)
post_daily = c(1, 0, 1, 0, 1, 0, 1)

## min. constriction means
coef_min <- summary(min_gee)$coefficients[,1] # coefficients from gee model

## Group Means at pre event for table 3 - min. constriction
mean_pre_non_min = sum(pre_non*coef_min)
mean_pre_occ_min = sum(pre_occ*coef_min)
mean_pre_daily_min = sum(pre_daily*coef_min)

## Group Means at post event for table 3 - min. constriction
mean_post_non_min = sum(post_non*coef_min)
mean_post_occ_min = sum(post_occ*coef_min)
mean_post_daily_min = sum(post_daily*coef_min)

## auc means
coef_auc <- summary(auc_gee)$coefficients[,1] # coefficients from gee model

## Group Means at pre event for table 3 - min. constriction
mean_pre_non_auc = sum(pre_non*coef_auc)
mean_pre_occ_auc = sum(pre_occ*coef_auc)
mean_pre_daily_auc = sum(pre_daily*coef_auc)

## Group Means at post event for table 3 - min. constriction
mean_post_non_auc = sum(post_non*coef_auc)
mean_post_occ_auc = sum(post_occ*coef_auc)
mean_post_daily_auc= sum(post_daily*coef_auc)

###Contrast statements for differences Differences; Post - pre###

# Non vs occ 

non_occ_dif = (post_non - pre_non) - (post_occ - pre_occ)

# Non vs daily

non_daily_dif = (post_non - pre_non) - (post_daily - pre_daily)

## Occ vs Daily
occ_daily_dif = (post_occ - pre_occ) - (post_daily - pre_daily)

```

# Functions for estimates and p-values of difference of differecences using contrast statements 

```{r}
### Function for pairwise difference of differences
contrast_pair = function(gee_model, contrast_statment, df, lower_tail = FALSE, log_p = FALSE){
  
  coef2 <- summary(gee_model)$coefficients[,1] # coefficients from gee model
  cov2 <- summary(gee_model)$cov.scaled # scaled covariance from gee model
  contrast_statment.m <- matrix(contrast_statment, byrow=T, 1, 7) # convert contrast statment to 1 by 7 matrix

  contrast_statment_est <- contrast_statment.m%*%coef2 # get estimate of difference from contrast statement * coefficients

  chisq.v <- t(contrast_statment_est)%*%solve(contrast_statment.m%*% cov2  %*%t(contrast_statment.m)) %*% contrast_statment_est # calculate chi-squared test statistic
  
  cont_p_value  <- pchisq(chisq.v, df, ncp=0, lower.tail=lower_tail, log.p=log_p) # calculate p value
  return (list(contrast_statment_est, cont_p_value))
}


#### Function for Overall difference of differences
contrast_overal = function(gee_model, dif1, dif2, dif3, df, lower_tail = FALSE, log_p = FALSE){
  
  coef2 <- summary(gee_model)$coefficients[,1] # coefficients from gee model
  cov2 <- summary(gee_model)$cov.scaled # scaled covariance from gee model
  contrast_statment.m <- matrix(c(dif1, dif2, dif3), byrow=T, 3, 7) # convert contrast statment to 1 by 7 matrix

  contrast_statment_est <- contrast_statment.m%*%coef2 # get estimate of difference from contrast statement * coefficients

  chisq.v <- t(contrast_statment_est)%*%solve(contrast_statment.m%*% cov2  %*%t(contrast_statment.m)) %*% contrast_statment_est # calculate chi-squared test statistic
  
  overall_p_value  <- pchisq(chisq.v, df, ncp=0, lower.tail=lower_tail, log.p=log_p) # calculate p value
  return (overall_p_value)
}
```



## Min. Constriction Results

```{r}

## Pairwise estimates for differences and p-values for table 4
non_daily_results = contrast_pair(min_gee, non_daily_dif, 1) # Dif_non - dif_daily

non_occ_results = contrast_pair(min_gee, non_occ_dif, 1)# Dif_non - dif_occ

occ_daily_results = contrast_pair(min_gee, occ_daily_dif, 1)# Dif_occ - dif_daily

## Letting the first group (eg: non, non, occ.) be the reference group, if the estimate is negative, that means the the comparison group has a larger difference (and negative) between their post and pre compared to reference group. This implies that the comparison group has less constriction at their post event compared to their baseline.....  

overall_min_constrict = contrast_overal(min_gee,non_dif, occ_dif, daily_dif, df = 3 )



### Creating row for table 

row_min_con = t(as.matrix(c(unlist(non_daily_results), unlist(non_occ_results), unlist(occ_daily_results), overall_min_constrict)))
colnames(row_min_con) = c("estimate", "p-value", "estimate", "p-value", "estimate", "p-value", "overall")

```


## AUC results

```{r}

## Pairwise estimates for differences and p-values for table 4
non_daily_results_auc = contrast_pair(auc_gee, non_daily_dif, 1) # Dif_non - dif_daily

non_occ_results_auc = contrast_pair(auc_gee, non_occ_dif, 1)# Dif_non - dif_occ

occ_daily_results_auc = contrast_pair(auc_gee, occ_daily_dif, 1)# Dif_occ - dif_daily

## Letting the first group (eg: non, non, occ.) be the reference group, if the estimate is negative, that means the the comparison group has a larger difference (and negative) between their post and pre compared to reference group. This implies that the comparison group has less constriction at their post event compared to their baseline.....  

overall_auc = contrast_overal(auc_gee,non_dif, occ_dif, daily_dif, df = 3 )



### Creating row for table 

row_auc = t(as.matrix(c(unlist(non_daily_results_auc), unlist(non_occ_results_auc), unlist(occ_daily_results_auc), overall_auc)))
colnames(row_auc) = c("estimate", "p-value", "estimate", "p-value", "estimate", "p-value", "overall")

```


## Table 3 ; Estimated Differences ; Non vs Occ vs Daily 

```{r}
tab_differences = round(rbind(row_min_con, row_auc),4)

rownames(tab_differences) = c("Minimum Constriction", "AUC per Frame")


kable(tab_differences,
      "html",
      booktabs = T,
      align = c("r")) %>%
  kable_styling("striped", full_width = F,
                position = "center", font_size = 12) %>%
  add_header_above(c("Scalar Feature"=1, "Non vs. Daily" = 2, "Non vs. Occ." = 2, "Occ. vs. Daily" =2, " "=1))

```
# Table 4

## Gee model with non vs user (general)

```{r}

#### Taking the easy way out and making a new variable 

scalars = scalars %>% mutate(group_general = case_when(
  user_type == "non-user" ~ "non-user",
  TRUE ~ "user"
))

min_gee_general <- geeglm(min_constriction ~ eye + prepost*group_general,
               data = scalars, 
               id = factor(subject_id), 
               family = gaussian,
               corstr = "independence")


auc_gee_general <- geeglm(AUC ~ eye + prepost*group_general,
               data = scalars, 
               id = factor(subject_id), 
               family = gaussian,
               corstr = "independence")

```

# Group means 

```{R}


coef_min_gen <- summary(min_gee_general)$coefficients[,1] # coefficients from gee model for min constriction - general user

coef_auc_gen <- summary(auc_gee_general)$coefficients[,1] # coefficients from gee model for min auc - general user

# Int + right + post + general + post*general 

## Pre contrast statements
pre_non_gen = c(1, 0, 0, 0, 0)
pre_use_gen = c(1, 0, 0, 1, 0)

## post contrast statements
post_non_gen = c(1, 0, 1, 0, 0)
post_use_gen = c(1, 0, 1, 1, 1)

### Means for general user - min. constriction
mean_pre_use_gen_min = sum(pre_use_gen*coef_min_gen)
mean_post_use_gen_min = sum(post_use_gen*coef_min_gen)

## Means for general user - auc
mean_pre_use_gen_auc = sum(pre_use_gen*coef_auc_gen)
mean_post_use_gen_auc = sum(post_use_gen*coef_auc_gen)


### contrast statments for Differences; ref(Post - pre) - comp(post - pre) ###

# Non vs general

non_occ_dif = (post_non_gen - pre_non_gen) - (post_use_gen - pre_use_gen)

```

# Functions for estimates and p-values of difference of differecences using contrast statements 

```{r}
### Function for pairwise difference of differences
contrast_pair = function(gee_model, contrast_statment, df, lower_tail = FALSE, log_p = FALSE){
  
  coef2 <- summary(gee_model)$coefficients[,1] # coefficients from gee model
  cov2 <- summary(gee_model)$cov.scaled # scaled covariance from gee model
  contrast_statment.m <- matrix(contrast_statment, byrow=T, 1, 5) # convert contrast statment to 1 by 7 matrix

  contrast_statment_est <- contrast_statment.m%*%coef2 # get estimate of difference from contrast statement * coefficients

  chisq.v <- t(contrast_statment_est)%*%solve(contrast_statment.m%*% cov2  %*%t(contrast_statment.m)) %*% contrast_statment_est # calculate chi-squared test statistic
  
  cont_p_value  <- pchisq(chisq.v, df, ncp=0, lower.tail=lower_tail, log.p=log_p) # calculate p value
  return (list(contrast_statment_est, cont_p_value))
}

```



## Min. Constriction Results

```{r}

## Pairwise estimates for differences and p-values for table 4
non_general_results = contrast_pair(min_gee_general, non_occ_dif, 1) # Dif_non - dif_daily

## Letting the first group (eg: non, non, occ.) be the reference group, if the estimate is negative, that means the the comparison group has a larger difference (and negative) between their post and pre compared to reference group. This implies that the comparison group has less constriction at their post event compared to their baseline.....  




### Creating row for table 

row_min_con_gen = t(as.matrix(unlist(non_general_results)))
colnames(row_min_con_gen) = c("estimate", "p-value")

```


## AUC results

```{r}
## Pairwise estimates for differences and p-values for table 4
non_general_results_auc = contrast_pair(auc_gee_general, non_occ_dif, 1) # Dif_non - dif_daily

## Letting the first group (eg: non, non, occ.) be the reference group, if the estimate is negative, that means the the comparison group has a larger difference (and negative) between their post and pre compared to reference group. This implies that the comparison group has less constriction at their post event compared to their baseline.....  




### Creating row for table 

row_auc_gen = t(as.matrix(unlist(non_general_results_auc)))
colnames(row_min_auc_gen) = c("estimate", "p-value")

```


## Table 3 ; Estimated Differences ; Non vs Occ vs Daily 

```{r}
tab_differences_gen = round(rbind(row_min_con_gen, row_auc_gen),4)

rownames(tab_differences_gen) = c("Minimum Constriction", "AUC per Frame")
colnames(tab_differences_gen) = c("estimate" , "p-value")

kable(tab_differences_gen,
      "html",
      booktabs = T,
      align = c("r")) %>%
  kable_styling("striped", full_width = F,
                position = "center", font_size = 12) %>%
  add_header_above(c("Scalar Feature"=1,"Non-User vs. User"=2 ))

```



# Table 2 - Adjusted means for pre and post 

```{r}
non_user_means = c(mean_pre_non_min, mean_pre_non_auc, mean_post_non_min, mean_post_non_auc)

occ_user_means = c(mean_pre_occ_min, mean_pre_occ_auc, mean_post_occ_min, mean_post_occ_auc)

daily_user_means = c(mean_pre_daily_min, mean_pre_daily_auc, mean_post_daily_min, mean_post_daily_auc)

gen_user_means = c(mean_pre_use_gen_min, mean_pre_use_gen_auc, mean_post_use_gen_min, mean_post_use_gen_auc)


means_table = as.matrix(rbind(non_user_means, occ_user_means, daily_user_means, gen_user_means))

colnames(means_table) = c("Minimum Constriction", "AUC per Frame", "Minimum Constriction", "AUC per Frame")

rownames(means_table) = c("non-user", 'occasional', 'daily', 'general user')

kable(means_table,
      "html",
      booktabs = T,
      align = c("r")) %>%
  kable_styling("striped", full_width = F,
                position = "center", font_size = 12) %>%
  add_header_above(c("User Group"=1,"Pre-Event"=2, "Post-Event" = 2))
```

# Boxplots 

```{r}
dif = scalars %>% filter(eye == "Right") %>% select(subject_id, user_type, time, eye, min_constriction) %>% pivot_wider(id_cols = c("subject_id", "user_type"), names_from = time, values_from = min_constriction) %>% mutate(difference = post - pre2)

ggplot(dif, aes(x = user_type, y = difference)) + geom_boxplot()

```
